{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Decision Tree Assignment\n", "Prepared by: Sanskriti Jaiswal\n", "Assignment Code: DA-AG-012"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 1: What is a Decision Tree, and how does it work in the context of classification?\n", "**Answer:**\n", "A Decision Tree is a flowchart-like structure used for both classification and regression. In classification, it splits the dataset into subsets using the value of input features. Each internal node represents a feature, each branch a decision rule, and each leaf node a class label. The model works by making decisions at each node based on feature values, ultimately predicting the class at the leaf node. It\u2019s simple, interpretable, and effective for various classification problems."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n", "**Answer:**\n", "- **Gini Impurity** measures the probability of a wrong classification if a random sample is classified according to the class distribution in a node. Lower Gini means purer nodes.\n", "- **Entropy** is a measure from information theory that quantifies uncertainty. Lower entropy means more information (purity).\n", "These metrics are used to evaluate how good a feature is at splitting data. The lower the impurity (Gini or Entropy), the better the split."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n", "**Answer:**\n", "- **Pre-Pruning** stops tree growth early by setting constraints like `max_depth`, `min_samples_split`, etc. *Advantage:* Saves time and avoids overfitting.\n", "- **Post-Pruning** allows the tree to grow fully and then removes branches that do not add value. *Advantage:* Improves accuracy on unseen data while still learning detailed patterns."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n", "**Answer:**\n", "Information Gain measures the reduction in entropy after a dataset is split on an attribute. It tells how much information a feature gives us about the class. The feature with the highest Information Gain is chosen to split the node. It\u2019s crucial because it helps in building the most informative and efficient tree."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n", "**Answer:**\n", "**Applications:**\n", "- Healthcare diagnosis\n", "- Credit scoring\n", "- Fraud detection\n", "- Marketing segmentation\n", "**Advantages:**\n", "- Easy to understand and visualize\n", "- Requires little data preprocessing\n", "- Works for both classification and regression\n", "**Limitations:**\n", "- Prone to overfitting\n", "- Can be biased if one class dominates\n", "- Instability with small data changes"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Question 6\n", "from sklearn.datasets import load_iris\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score\n", "\n", "iris = load_iris()\n", "X, y = iris.data, iris.target\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "clf = DecisionTreeClassifier(criterion='gini')\n", "clf.fit(X_train, y_train)\n", "y_pred = clf.predict(X_test)\n", "\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"Feature Importances:\", clf.feature_importances_)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Question 7\n", "full_tree = DecisionTreeClassifier()\n", "limited_tree = DecisionTreeClassifier(max_depth=3)\n", "\n", "full_tree.fit(X_train, y_train)\n", "limited_tree.fit(X_train, y_train)\n", "\n", "print(\"Full Tree Accuracy:\", accuracy_score(y_test, full_tree.predict(X_test)))\n", "print(\"Depth-3 Tree Accuracy:\", accuracy_score(y_test, limited_tree.predict(X_test)))"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Question 8\n", "from sklearn.datasets import fetch_california_housing\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.metrics import mean_squared_error\n", "\n", "data = fetch_california_housing()\n", "X, y = data.data, data.target\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n", "\n", "reg = DecisionTreeRegressor()\n", "reg.fit(X_train, y_train)\n", "y_pred = reg.predict(X_test)\n", "\n", "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n", "print(\"Feature Importances:\", reg.feature_importances_)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Question 9\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "params = {'max_depth': [2, 3, 4, 5], 'min_samples_split': [2, 5, 10]}\n", "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=params, cv=5)\n", "grid.fit(X_train, y_train)\n", "\n", "print(\"Best Params:\", grid.best_params_)\n", "print(\"Best Score:\", grid.best_score_)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Question 10:\n", "**Answer:**\n", "Step-by-step approach:\n", "1. **Handle Missing Values:**\n", "   - Use imputation techniques (mean for numerical, mode for categorical).\n", "2. **Encode Categorical Features:**\n", "   - Use LabelEncoder or OneHotEncoder.\n", "3. **Train a Decision Tree:**\n", "   - Split data into training and testing, fit the tree model.\n", "4. **Tune Hyperparameters:**\n", "   - Use GridSearchCV to optimize parameters like `max_depth`, `min_samples_split`.\n", "5. **Evaluate Performance:**\n", "   - Use accuracy, precision, recall, confusion matrix.\n", "**Business Value:**\n", "The model can provide early disease detection, reduce healthcare costs, and improve patient outcomes by assisting doctors in making data-driven decisions."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": ""}}, "nbformat": 4, "nbformat_minor": 2}