{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2a94f4",
   "metadata": {},
   "source": [
    "# Cryptocurrency Volatility Prediction\n",
    "\n",
    "**Notebook**: reproducible pipeline for data, features, EDA, modeling, and deployment snippets.\n",
    "\n",
    "**Author**: Sanskriti Jaiswal\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3528ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports and configuration\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display options\n",
    "pd.set_option('display.max_columns', 200)\n",
    "DATA_PATH = Path('data/crypto_daily.csv')  # <-- put your CSV here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948925f0",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "Load dataset (daily OHLCV + market cap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c06450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if DATA_PATH.exists():\n",
    "    df = pd.read_csv(DATA_PATH, parse_dates=['date'])\n",
    "    print('Loaded:', df.shape)\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(f'File not found: {DATA_PATH}. Please place the CSV at this path and re-run.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ea2e99",
   "metadata": {},
   "source": [
    "## 2) Preprocessing helper functions\n",
    "- Handle missing values\n",
    "- Type casting\n",
    "- Basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_basic(df):\n",
    "    df = df.copy()\n",
    "    # ensure datetime and sort\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.sort_values(['symbol','date']).reset_index(drop=True)\n",
    "    # forward/backward fill small missing runs per symbol\n",
    "    df[['open','high','low','close','volume','market_cap']] = df.groupby('symbol')[['open','high','low','close','volume','market_cap']].apply(lambda g: g.fillna(method='ffill').fillna(method='bfill'))\n",
    "    # compute simple returns\n",
    "    df['return'] = df.groupby('symbol')['close'].pct_change()\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# df = preprocess_basic(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6537a01",
   "metadata": {},
   "source": [
    "## 3) Feature engineering\n",
    "Create volatility and liquidity related features (rolling std, ATR, Bollinger Bands, liquidity ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7feaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, win=14):\n",
    "    df = df.copy()\n",
    "    # Rolling std of returns as a volatility proxy\n",
    "    df['vol_rolling_std'] = df.groupby('symbol')['return'].rolling(window=win, min_periods=1).std().reset_index(0,drop=True)\n",
    "    # ATR (Average True Range)\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_prevclose = (df['high'] - df.groupby('symbol')['close'].shift(1)).abs()\n",
    "    low_prevclose = (df['low'] - df.groupby('symbol')['close'].shift(1)).abs()\n",
    "    df['true_range'] = pd.concat([high_low, high_prevclose, low_prevclose], axis=1).max(axis=1)\n",
    "    df['atr'] = df.groupby('symbol')['true_range'].rolling(window=win, min_periods=1).mean().reset_index(0,drop=True)\n",
    "    # Bollinger Bands (on close)\n",
    "    df['ma'] = df.groupby('symbol')['close'].rolling(window=win, min_periods=1).mean().reset_index(0,drop=True)\n",
    "    df['bb_std'] = df.groupby('symbol')['close'].rolling(window=win, min_periods=1).std().reset_index(0,drop=True)\n",
    "    df['bb_upper'] = df['ma'] + 2 * df['bb_std']\n",
    "    df['bb_lower'] = df['ma'] - 2 * df['bb_std']\n",
    "    # Liquidity ratio\n",
    "    df['liquidity'] = df['volume'] / (df['market_cap'] + 1e-9)\n",
    "    # lag features\n",
    "    for lag in [1,2,3,7,14]:\n",
    "        df[f'return_lag_{lag}'] = df.groupby('symbol')['return'].shift(lag)\n",
    "    # target: next-day rolling volatility (for supervised learning)\n",
    "    df['target_vol_7'] = df.groupby('symbol')['vol_rolling_std'].shift(-1)  # example: next day volatility proxy\n",
    "    return df\n",
    "\n",
    "# Example:\n",
    "# df = add_features(df, win=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883e9ab",
   "metadata": {},
   "source": [
    "## 4) Exploratory Data Analysis (EDA)\n",
    "Plot example symbol, distributions, correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ad8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_symbol(df, symbol='BTC'):\n",
    "    d = df[df['symbol'] == symbol].copy().set_index('date')\n",
    "    fig, ax = plt.subplots(3,1, figsize=(12,10), sharex=True)\n",
    "    d['close'].plot(ax=ax[0], title=f'{symbol} Close Price')\n",
    "    d['vol_rolling_std'].plot(ax=ax[1], title=f'{symbol} Rolling Volatility (std)')\n",
    "    d['atr'].plot(ax=ax[2], title=f'{symbol} ATR')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_example_symbol(df, 'BTC')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278d1c0",
   "metadata": {},
   "source": [
    "## 5) Modeling\n",
    "Time-aware split -> RandomForest baseline -> metrics (RMSE, MAE, R2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "\n",
    "def prepare_dataset(df, symbol='BTC', feature_cols=None, target_col='target_vol_7'):\n",
    "    d = df[df['symbol'] == symbol].copy().dropna(subset=[target_col])\n",
    "    if feature_cols is None:\n",
    "        feature_cols = ['vol_rolling_std','atr','liquidity','ma'] + [c for c in d.columns if 'return_lag' in c]\n",
    "    X = d[feature_cols]\n",
    "    y = d[target_col]\n",
    "    # time-based split\n",
    "    split = int(0.8 * len(d))\n",
    "    X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
    "    y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Example quick baseline training function\n",
    "def train_rf(X_train, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Example evaluation\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return {'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# Save model\n",
    "def save_model(model, path='models/rf_vol_model.pkl'):\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(model, path)\n",
    "    print('Saved model to', path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf001c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example end-to-end small-run (only runs when data exists)\n",
    "if 'df' in globals() and not df.empty:\n",
    "    df = preprocess_basic(df)\n",
    "    df = add_features(df, win=14)\n",
    "    symbol = df['symbol'].unique()[0]\n",
    "    X_train, X_test, y_train, y_test = prepare_dataset(df, symbol=symbol)\n",
    "    print('Train/Test sizes:', X_train.shape, X_test.shape)\n",
    "    model = train_rf(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    print('Metrics:', metrics)\n",
    "    save_model(model, path='models/rf_vol_model.pkl')\n",
    "else:\n",
    "    print('Dataset not loaded; skip model run.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537596f7",
   "metadata": {},
   "source": [
    "## 6) Deployment (Streamlit demo)\n",
    "Simple Streamlit app snippet that loads saved model and predicts from user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b78057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this as src/app.py for a simple Streamlit interface\n",
    "streamlit_app_code = '''import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "st.title('Crypto Volatility Predictor — Demo')\n",
    "model_path = Path('models/rf_vol_model.pkl')\n",
    "if not model_path.exists():\n",
    "    st.warning('Model artifact not found. Train and save a model first.')\n",
    "else:\n",
    "    model = joblib.load(model_path)\n",
    "    st.sidebar.header('Input features')\n",
    "    vol_rolling_std = st.sidebar.number_input('vol_rolling_std', value=0.02)\n",
    "    atr = st.sidebar.number_input('atr', value=10.0)\n",
    "    liquidity = st.sidebar.number_input('liquidity', value=1e-6, format='%.8f')\n",
    "    ma = st.sidebar.number_input('ma', value=30000.0)\n",
    "    # create df\n",
    "    X = pd.DataFrame([[vol_rolling_std, atr, liquidity, ma]], columns=['vol_rolling_std','atr','liquidity','ma'])\n",
    "    pred = model.predict(X)[0]\n",
    "    st.metric('Predicted next-day volatility (proxy)', f'{pred:.6f}')\n",
    "'''\n",
    "print('Streamlit app snippet saved to src/app.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382082a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the streamlit snippet to file\n",
    "Path('src').mkdir(parents=True, exist_ok=True)\n",
    "with open('src/app.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(streamlit_app_code)\n",
    "print('Wrote src/app.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e025b33",
   "metadata": {},
   "source": [
    "## 7) Conclusion & Next Steps\n",
    "- This notebook provides a reproducible baseline pipeline. \n",
    "- Next: advanced time-series CV, XGBoost tuning, LSTM/Transformer experiments, probabilistic forecasts, and production deployment.\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck — customize the notebook with your dataset and tune models for improved performance!**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
